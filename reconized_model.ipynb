{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j28302830/Senior_Project/blob/main/reconized_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Samples and Models file"
      ],
      "metadata": {
        "id": "Y2fj9xgNFy1H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjh7QysoGGly",
        "outputId": "dfc071cc-bd69-4ced-f199-aa850f240a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-28 13:55:01--  http://dataset.tlm.unavarra.es/ransomware/samplesAndModels.tar.xz\n",
            "Resolving dataset.tlm.unavarra.es (dataset.tlm.unavarra.es)... 130.206.160.87\n",
            "Connecting to dataset.tlm.unavarra.es (dataset.tlm.unavarra.es)|130.206.160.87|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41519408 (40M) [application/x-xz]\n",
            "Saving to: ‘samplesAndModels.tar.xz.6’\n",
            "\n",
            "samplesAndModels.ta 100%[===================>]  39.60M  9.75MB/s    in 4.8s    \n",
            "\n",
            "2022-04-28 13:55:06 (8.29 MB/s) - ‘samplesAndModels.tar.xz.6’ saved [41519408/41519408]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://dataset.tlm.unavarra.es/ransomware/samplesAndModels.tar.xz\n",
        "!tar -Jxvf /content/samplesAndModels.tar.xz &> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Package"
      ],
      "metadata": {
        "id": "6_Ho5k4cIa5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import glob\n",
        "import numpy as np\n",
        "from pickle import load\n",
        "import joblib "
      ],
      "metadata": {
        "id": "aBO0NnXOIery"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predefined Function"
      ],
      "metadata": {
        "id": "uES_q4V7X2FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_sample(local_path):\n",
        "  filenames = glob.glob(local_path + \"/*.txt\")\n",
        "  for i,filename in enumerate(filenames):\n",
        "    if i == 0:\n",
        "      x = np.loadtxt(filename, delimiter=',', dtype = 'float32')\n",
        "    else: \n",
        "      ds = np.loadtxt(filename, delimiter=',', dtype = 'float32')\n",
        "      x = np.concatenate((x, ds), axis=0)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "4DnoKttCUqgU"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model , x, y):\n",
        "  predict = model.predict(x)\n",
        "  predict[predict >= 0.99] = 1\n",
        "  predict[predict < 0.99] = 0\n",
        "\n",
        "  true_values = y\n",
        "  predictions = predict\n",
        "\n",
        "  TP = ((predictions == 1) & (true_values == 1)).sum()\n",
        "  FP = ((predictions == 1) & (true_values == 0)).sum()\n",
        "  TN = ((predictions == 0) & (true_values == 0)).sum()\n",
        "  FN = ((predictions == 0) & (true_values == 1)).sum()\n",
        "  accuracy = (TP+TN) / (TP+FP+TN+FN)\n",
        "  evaluate = model.evaluate(x=x, y=y)\n",
        "  return [evaluate[1], accuracy]"
      ],
      "metadata": {
        "id": "Oa6ruX_IOzBJ"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load NN, CNN, and LSTM model"
      ],
      "metadata": {
        "id": "z_S1CHvjGIFu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcgHv9NC7w7e",
        "outputId": "26e76511-f962-468d-a893-4a113d18346f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        }
      ],
      "source": [
        "model_NN = tf.keras.models.load_model('/content/NN_CNN_LSTM_Comparison/NN')\n",
        "model_CNN = tf.keras.models.load_model('/content/NN_CNN_LSTM_Comparison/CNN')\n",
        "model_LSTM = tf.keras.models.load_model('/content/NN_CNN_LSTM_Comparison/LSTM')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "JSON"
      ],
      "metadata": {
        "id": "cv1nGsFRQPya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "json_file = open('/content/NN.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = tf.keras.models.model_from_json(loaded_model_json)"
      ],
      "metadata": {
        "id": "K2L-0RkHQKwC"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load test and train sample"
      ],
      "metadata": {
        "id": "gRu9WhzCUByU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "hQVKnMMq-VkP"
      },
      "outputs": [],
      "source": [
        "x_test = load_sample(local_path = r'/content/samples/ransomwareSamples_test')\n",
        "x_train = load_sample(local_path = r'/content/samples/ransomwareSamples_train')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Sample"
      ],
      "metadata": {
        "id": "XklgZaqKCnFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = joblib.load('/content/scaler.scaler')\n",
        "\n",
        "index = list(range(0, 30))\n",
        "\n",
        "label = np.delete(x_test, index + [31], axis=1)\n",
        "feature = np.delete(x_test, [30,31], axis=1)\n",
        "feature_10X3 = np.reshape(feature, (feature.shape[0], 10, 3))\n",
        "\n",
        "\n",
        "\n",
        "feature_scaled = scaler.transform(feature)\n",
        "feature_scaled_10X3 = np.reshape(feature_scaled, (feature_scaled.shape[0], 10, 3))\n",
        "\n",
        "print('資料集 x_test 的平均值 : ', x_test.mean(axis=0))\n",
        "print('資料集 x_test 的標準差 : ', x_test.std(axis=0))\n",
        "print('\\nStandardScaler 縮放過後資料集 x_test 的平均值 : ', feature_scaled.mean(axis=0))\n",
        "print('StandardScaler 縮放過後資料集 x_test 的標準差 : ', feature_scaled.std(axis=0))\n",
        "\n",
        "print(\"feature_10X3's shape\" ,feature_10X3.shape)\n",
        "print(\"feature's shape\" , x_test.shape)\n",
        "print(\"feature's dtype\" , x_test.dtype)\n",
        "print(\"label's shape\" , label.shape)\n",
        "print(\"label's dtype\" , label.dtype)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaN9BCU3UKo7",
        "outputId": "706a1a10-19a4-4d7b-8511-a47c37dda602"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "資料集 x_test 的平均值 :  [5.9634650e+05 5.9646450e+05 6.1626219e+05 6.0082194e+05 6.1096806e+05\n",
            " 6.0031862e+05 5.9714181e+05 6.0455369e+05 6.1581250e+05 5.9984931e+05\n",
            " 6.6018625e+05 6.5127812e+05 6.4531444e+05 6.5634431e+05 6.5318562e+05\n",
            " 6.5138962e+05 6.4804638e+05 6.4783319e+05 6.4951050e+05 6.4643519e+05\n",
            " 2.1893274e+01 2.1662115e+01 2.1797686e+01 2.1869705e+01 2.1969095e+01\n",
            " 2.1747356e+01 2.1959156e+01 2.1660055e+01 2.1675020e+01 2.1535330e+01\n",
            " 1.0000000e+00 7.5295445e+06]\n",
            "資料集 x_test 的標準差 :  [1.9809578e+06 1.9829548e+06 2.0642916e+06 2.0071552e+06 2.0257402e+06\n",
            " 2.0563311e+06 1.9994486e+06 2.0354585e+06 2.0783109e+06 2.0108499e+06\n",
            " 2.0343956e+06 1.9871325e+06 1.9990465e+06 1.9986080e+06 1.9949164e+06\n",
            " 2.0059031e+06 1.9837660e+06 1.9673376e+06 1.9897425e+06 1.9853988e+06\n",
            " 8.1434433e+01 8.0579559e+01 8.1688385e+01 8.0962242e+01 8.1808128e+01\n",
            " 8.1566849e+01 8.1763870e+01 8.0222404e+01 7.9913879e+01 7.9761314e+01\n",
            " 0.0000000e+00 1.0596360e+08]\n",
            "\n",
            "StandardScaler 縮放過後資料集 x_test 的平均值 :  [1.0534327 1.0989313 1.1129344 1.1120821 1.0954617 1.098395  1.1064941\n",
            " 1.1149415 1.1288438 1.1217539 2.6842062 2.6264548 2.645101  2.6949532\n",
            " 2.6584096 2.6006691 2.6481469 2.6287866 2.5951183 2.485957  1.3327429\n",
            " 1.3414946 1.3701867 1.3696674 1.3891228 1.3881873 1.4000058 1.3814152\n",
            " 1.3668971 1.3628016]\n",
            "StandardScaler 縮放過後資料集 x_test 的標準差 :  [3.6718733 3.831435  3.9038703 3.891022  3.8048017 3.9453905 3.887968\n",
            " 3.9348316 3.9886255 3.9387944 8.452291  8.190197  8.378067  8.388432\n",
            " 8.299511  8.18798   8.286638  8.162125  8.130012  7.8124943 5.351414\n",
            " 5.3290157 5.4765115 5.408492  5.5141745 5.551768  5.554023  5.455227\n",
            " 5.378207  5.386984 ]\n",
            "feature_10X3's shape (44169, 10, 3)\n",
            "feature's shape (44169, 32)\n",
            "feature's dtype float32\n",
            "label's shape (44169, 1)\n",
            "label's dtype float32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator StandardScaler from version 0.23.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Model all with ransomware file"
      ],
      "metadata": {
        "id": "bfGvOB_uQ_Wj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Original Feature"
      ],
      "metadata": {
        "id": "q9iAFj_ZSmfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NN = accuracy(model_NN, x=feature, y=label)\n",
        "CNN = accuracy(model_CNN, x=feature_10X3, y=label)\n",
        "LSTM = accuracy(model_LSTM, x=feature_10X3, y=label)\n",
        "print(\"NN:\\nevalute(): %f vs accuracy(): %f\" %(NN[0], NN[1]) )\n",
        "print(\"CNN:\\nevalute(): %f vs accuracy(): %f\" %(CNN[0], CNN[1]) )\n",
        "print(\"LSTM:\\nevalute(): %f vs accuracy(): %f\" %(LSTM[0], LSTM[1]) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-IgjEnXCvuY",
        "outputId": "e8f5afe5-2f7a-4c86-e938-61fc817771fd"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1381/1381 [==============================] - 3s 2ms/step - loss: 18.8371 - accuracy: 0.2556\n",
            "1381/1381 [==============================] - 3s 2ms/step - loss: 3.5844 - accuracy: 0.2833\n",
            "1381/1381 [==============================] - 6s 4ms/step - loss: 8.3336 - accuracy: 0.3133\n",
            "NN:\n",
            "evalute(): 0.255587 vs accuracy(): 0.240916\n",
            "CNN:\n",
            "evalute(): 0.283276 vs accuracy(): 0.240123\n",
            "LSTM:\n",
            "evalute(): 0.313342 vs accuracy(): 0.215898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaled feature \n"
      ],
      "metadata": {
        "id": "pky4qC3rKFea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NN = accuracy(model_NN, x=feature_scaled, y=label)\n",
        "CNN = accuracy(model_CNN, x=feature_scaled_10X3, y=label)\n",
        "LSTM = accuracy(model_LSTM, x=feature_scaled_10X3, y=label)\n",
        "print(\"NN:\\nevalute(): %f vs accuracy(): %f\" %(NN[0], NN[1]) )\n",
        "print(\"CNN:\\nevalute(): %f vs accuracy(): %f\" %(CNN[0], CNN[1]) )\n",
        "print(\"LSTM:\\nevalute(): %f vs accuracy(): %f\" %(LSTM[0], LSTM[1]) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD_DbAVsKMJP",
        "outputId": "7a2cf5e1-c586-4a39-a5ec-471e859bbb0d"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1381/1381 [==============================] - 3s 2ms/step - loss: 41.5196 - accuracy: 0.2444\n",
            "1381/1381 [==============================] - 3s 2ms/step - loss: 10.4108 - accuracy: 0.2424\n",
            "1381/1381 [==============================] - 5s 4ms/step - loss: 9.3257 - accuracy: 0.2609\n",
            "NN:\n",
            "evalute(): 0.244425 vs accuracy(): 0.229301\n",
            "CNN:\n",
            "evalute(): 0.242410 vs accuracy(): 0.219860\n",
            "LSTM:\n",
            "evalute(): 0.260907 vs accuracy(): 0.229980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Model with each ransomware file"
      ],
      "metadata": {
        "id": "FBFwed7Yf31F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cFa8JGuZG8tV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Scaler"
      ],
      "metadata": {
        "id": "yi-oXUHCjXS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "index = np.array( [ list( range(0, 30) )]  )\n",
        "scaler1 = StandardScaler()\n",
        "print(scaler.transform(index))\n",
        "print(scaler1.transform(index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "WbuJqiwvjK87",
        "outputId": "9f51ecd5-a0b1-4988-e84c-7cd5b9695b70"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.05201372 -0.05361435 -0.05238718 -0.05263657 -0.05211621 -0.05342558\n",
            "  -0.05487471 -0.05368822 -0.05291273 -0.05325989 -0.0582454  -0.05800431\n",
            "  -0.0589161  -0.05958257 -0.0593168  -0.05840374 -0.05838046 -0.05849376\n",
            "  -0.05911215 -0.05746198  1.20832544  1.29770153  1.38375147  1.44517749\n",
            "   1.52600189  1.60961178  1.6744698   1.74458008  1.79261236  1.8668522 ]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-49cbb7417eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscaler1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m         \"\"\"\n\u001b[0;32m--> 970\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "reconized_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}